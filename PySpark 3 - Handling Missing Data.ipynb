{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ed5b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jared\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pyspark\\context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f79fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('fake.csv', header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc759c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----------+-------+--------------+\n",
      "|    Name|Age|Experience | Salary|   Departments|\n",
      "+--------+---+-----------+-------+--------------+\n",
      "|    John| 40|          5|  35000|         Heart|\n",
      "|  Amanda| 25|          6|  36000|Administrative|\n",
      "| Pugsley|  4|          1|1000000|        Doctor|\n",
      "|   Avery| 31|         10|  78000|  Supply Chain|\n",
      "|Phylicia| 35|         15|  90000|Administrative|\n",
      "|  Jordan| 31|         16|  87000|         Heart|\n",
      "| Brendan| 30|         21|  67000|  Supply Chain|\n",
      "|   Jimmy| 35|          9|  74000|     Logistics|\n",
      "|   Sidni| 17|          8| 210000|       Stunin'|\n",
      "+--------+---+-----------+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc641e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----------+-------+--------------+\n",
      "|    Name|Age|Experience | Salary|   Departments|\n",
      "+--------+---+-----------+-------+--------------+\n",
      "|    John| 40|          5|  35000|         Heart|\n",
      "|  Amanda| 25|          6|  36000|Administrative|\n",
      "| Pugsley|  4|          1|1000000|        Doctor|\n",
      "|   Avery| 31|         10|  78000|  Supply Chain|\n",
      "|Phylicia| 35|         15|  90000|Administrative|\n",
      "|  Jordan| 31|         16|  87000|         Heart|\n",
      "| Brendan| 30|         21|  67000|  Supply Chain|\n",
      "|   Jimmy| 35|          9|  74000|     Logistics|\n",
      "|   Sidni| 17|          8| 210000|       Stunin'|\n",
      "+--------+---+-----------+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show() ## na.drop() removes all rows that are non-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaca0742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----------+-------+--------------+\n",
      "|    Name|Age|Experience | Salary|   Departments|\n",
      "+--------+---+-----------+-------+--------------+\n",
      "|    John| 40|          5|  35000|         Heart|\n",
      "|  Amanda| 25|          6|  36000|Administrative|\n",
      "| Pugsley|  4|          1|1000000|        Doctor|\n",
      "|   Avery| 31|         10|  78000|  Supply Chain|\n",
      "|Phylicia| 35|         15|  90000|Administrative|\n",
      "|  Jordan| 31|         16|  87000|         Heart|\n",
      "| Brendan| 30|         21|  67000|  Supply Chain|\n",
      "|   Jimmy| 35|          9|  74000|     Logistics|\n",
      "|   Sidni| 17|          8| 210000|       Stunin'|\n",
      "+--------+---+-----------+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### any==how\n",
    "df_pyspark.na.drop(how=\"all\").show()  #all will delete everything, any is specific (how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc4b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----------+-------+--------------+\n",
      "|    Name|Age|Experience | Salary|   Departments|\n",
      "+--------+---+-----------+-------+--------------+\n",
      "|    John| 40|          5|  35000|         Heart|\n",
      "|  Amanda| 25|          6|  36000|Administrative|\n",
      "| Pugsley|  4|          1|1000000|        Doctor|\n",
      "|   Avery| 31|         10|  78000|  Supply Chain|\n",
      "|Phylicia| 35|         15|  90000|Administrative|\n",
      "|  Jordan| 31|         16|  87000|         Heart|\n",
      "| Brendan| 30|         21|  67000|  Supply Chain|\n",
      "|   Jimmy| 35|          9|  74000|     Logistics|\n",
      "|   Sidni| 17|          8| 210000|       Stunin'|\n",
      "+--------+---+-----------+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##threshold\n",
    "df_pyspark.na.drop(how=\"any\",thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71222be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.show of DataFrame[Name: string, Age: int, Experience : int, Salary: int, Departments: string]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Subset\n",
    "df_pyspark.na.drop(how=\"any\", subset=['Departments']).show #drop values from a specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174aae5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.show of DataFrame[Name: string, Age: int, Experience : int, Salary: int, Departments: string]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fill in with missing value\n",
    "df_pyspark.na.fill('MissingValues').show #It'll put whatever you want there. Can also add ,[Columnname] to be specific with subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68703123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----------+-------+--------------+\n",
      "|    Name|Age|Experience | Salary|   Departments|\n",
      "+--------+---+-----------+-------+--------------+\n",
      "|    John| 40|          5|  35000|         Heart|\n",
      "|  Amanda| 25|          6|  36000|Administrative|\n",
      "| Pugsley|  4|          1|1000000|        Doctor|\n",
      "|   Avery| 31|         10|  78000|  Supply Chain|\n",
      "|Phylicia| 35|         15|  90000|Administrative|\n",
      "|  Jordan| 31|         16|  87000|         Heart|\n",
      "| Brendan| 30|         21|  67000|  Supply Chain|\n",
      "|   Jimmy| 35|          9|  74000|     Logistics|\n",
      "|   Sidni| 17|          8| 210000|       Stunin'|\n",
      "+--------+---+-----------+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66620e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.feature import Imputer\n",
    "\n",
    "#imputer = Imputer(\n",
    "    #inputCols=['age','Experience', 'Salary'],\n",
    "    #outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
    "    #).setStrategy('mean')\n",
    "    \n",
    "#function above will give mean value for null items. \n",
    "\n",
    "# To Add imputation cols to df\n",
    "#imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
